{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Siamese_STS.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOvjqgqRSlLqGSedkBqVyv8"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"zZlD8i2rVJBj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606436511507,"user_tz":-540,"elapsed":24345,"user":{"displayName":"Koya Kokubu","photoUrl":"","userId":"03447341678313529916"}},"outputId":"7153f507-3070-4637-bc52-40afcac7e0a6"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ae6Gnje2H-tn","colab":{"base_uri":"https://localhost:8080/","height":305},"executionInfo":{"status":"error","timestamp":1606459167548,"user_tz":-540,"elapsed":3190,"user":{"displayName":"Koya Kokubu","photoUrl":"","userId":"03447341678313529916"}},"outputId":"a67436f5-2b42-4f0c-bf99-71f9599e9e18"},"source":["from time import time\n","import pandas as pd\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.python.keras.models import Model, Sequential\n","from tensorflow.python.keras.layers import Input, Embedding, LSTM, Dense, Dot, Reshape, Lambda\n","from tensorflow.python.keras import backend as K\n","from tensorflow.python.keras.layers import Layer\n","from keras.optimizers import Adam\n","from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n","from keras.callbacks import EarlyStopping\n","from nltk.corpus import stopwords\n","import nltk\n","nltk.download('stopwords')\n","stop_words = nltk.corpus.stopwords.words('english')\n","from gensim.models import KeyedVectors\n","import numpy as np\n","from keras.preprocessing.text import Tokenizer\n","import itertools\n","import re\n","\n","def split_and_zero_padding(df, max_seq_length):\n","    # Split to dicts\n","    X = {'left': df['left_n'], 'right': df['right_n']}\n","    # Zero padding\n","    for dataset, side in itertools.product([X], ['left', 'right']):\n","        dataset[side] = pad_sequences(dataset[side], padding='pre', truncating='post', maxlen=max_seq_length)\n","    return dataset\n","\n","#  --\n","\n","def clean_data(file):\n","    lines = [0]*2\n","    lines[0] = []\n","    lines[1] = []\n","    with open(file, \"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            line = line.lower()\n","            line = line.rstrip().split(\"\\t\")\n","            doc_w = []\n","            doc_w.append(line[0].split())\n","            doc_w.append(line[1].split())\n","            #line2 = []\n","            for i in range(2):\n","                words = []\n","                for w in doc_w[i]:\n","                    w = w.replace(\"'s\", '')\n","                    w = re.sub(re.compile(\"[!-/:-@[-`{-~]\"), '', w)\n","            #    line2.append(w)\n","            #stemmer = PorterStemmer()\n","            #line = list(map(stemmer.stem, line2))\n","            #wnl = WordNetLemmatizer()\n","            #line = list(map(wnl.lemmatize, line2))\n","            #for w in line:\n","                    if w not in stop_words:\n","                        if w != '':\n","                            words.append(w)\n","                lines[i].append(words)\n","    return lines\n","\n","def clean_data2(file):\n","    words = []\n","    with open(file, \"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            line = line.lower()\n","            line = line.rstrip().split()\n","            #line2 = []\n","            for w in line:\n","                w = w.replace(\"'s\", '')\n","                w = re.sub(re.compile(\"[!-/:-@[-`{-~]\"), '', w)\n","            #    line2.append(w)\n","            #stemmer = PorterStemmer()\n","            #line = map(stemmer.stem, line2)\n","            #wnl = WordNetLemmatizer()\n","            #line = map(wnl.lemmatize, line)\n","            #for w in line:\n","                if w not in stop_words:\n","                    if w != '':\n","                        words.append(w)\n","    return words\n","\n","dataset = [\n","'./drive/MyDrive/Colab Notebooks/training_data/STS.input.OnWN.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.input.deft-forum.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.input.deft-news.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.input.headlines.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.input.MSRpar.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.input.MSRvid.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.input.SMTeuroparl.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.input.tweet-news.txt',\n","]\n","q0 = []\n","q1 = []\n","file = []\n","for fname in dataset:\n","    questions = clean_data(fname)\n","    q0.extend(questions[0])\n","    q1.extend(questions[1])\n","    file.append(clean_data2(fname))\n","train_df = pd.DataFrame({'left' : [], 'right' : []})\n","train_df['left'] = np.array(q0)\n","train_df['right'] = np.array(q1)\n","\n","# Load training set\n","#for q in ['left', 'right']:\n","#    train_df[q + '_n'] =\n"," \n","\n","tokenizer_L = Tokenizer()\n","tokenizer_R = Tokenizer()\n","tokenizer_L.fit_on_texts(train_df['left'])\n","tokenizer_R.fit_on_texts(train_df['right'])\n","#dic_L = tokenizer_L.word_index\n","#dic_R = tokenizer_R.word_index\n","#words_L = []\n","#words_R = []\n","#for list in train_df['left']:\n","#    words = []\n","#    for w in list:\n","#        words.append(dic_L[w])\n","#    words_L.append(words)\n","#for list in train_df['right']:\n","#    words = []\n","#    for w in list:\n","#        words.append(dic_R[w])\n","#    words_R.append(words)\n","#train_df['left_n'] = words_L\n","#train_df['right_n'] = words_R\n","train_df['left_n'] = tokenizer_L.texts_to_matrix(train_df['left'], \"binary\")\n","train_df['right_n'] = tokenizer_R.texts_to_matrix(train_df['right'], \"binary\")\n","print(train_df['left_n'])\n","print(train_df['right_n'])\n","\n","#count1 = 0\n","#for list in train_df['left']:\n","#    count2 = 0\n","#    for word in list:\n","#        embeddings[train_df['left'][count1][count2]] = matrix[word]\n","#        count2 += 1\n","#    count1 += 1\n","#print(embeddings)\n","\n","embedding_dim = 200\n","max_seq_length = 20\n","#use_w2v = True\n","#train_df, embeddings = make_w2v_embeddings(train_df, file, embedding_dim=embedding_dim, empty_w2v=not use_w2v)\n","\n","# Split to train validation\n","validation_size = int(len(train_df) * 0.1)\n","training_size = len(train_df) - validation_size\n","\n","X = train_df[['left_n', 'right_n']]\n","\n","#left = []\n","#right = []\n","#for list in train_df['left'].values:\n","#    left.append(np.array(list))\n","#for list in train_df['right'].values:\n","#    right.append(np.array(list))\n","#X_train = {'left': np.array(left), 'right': np.array(right)}\n","#print(X_train)\n","\n","def gs_label(file):\n","    labels = []\n","    with open(file, \"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            line = line.rstrip().split()\n","            labels.append(line)\n","    return labels\n","\n","train_gs = [\n","'./drive/MyDrive/Colab Notebooks/training_data/STS.gs.OnWN.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.gs.deft-forum.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.gs.deft-news.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.gs.headlines.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.gs.MSRpar.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.gs.MSRvid.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.gs.SMTeuroparl.txt',\n","'./drive/MyDrive/Colab Notebooks/add_data/STS.gs.tweet-news.txt'\n","]\n","train_labels = []\n","for fname in train_gs:\n","    train_labels.extend(gs_label(fname))\n","\n","X_train, X_validation, Y_train, Y_validation = train_test_split(X, train_labels, test_size=validation_size)\n","X_train = split_and_zero_padding(X_train, max_seq_length)\n","X_validation = split_and_zero_padding(X_validation, max_seq_length)\n","\n","y_t = []\n","for list in Y_train:\n","    for l in list:\n","        y_t.append(float(l)/5)\n","Y_train = np.array(y_t)\n","\n","y_v = []\n","for list in Y_validation:\n","    for l in list:\n","        y_v.append(float(l)/5)\n","Y_validation = np.array(y_v)\n","\n","#y_t = []\n","#for gs in train_labels:\n","#    gs = str(gs)\n","#    gs = gs.replace(\"['\", '')\n","#    gs = gs.replace(\"']\", '')\n","#    y_t.append(float(gs)/5)\n","#Y_train = np.array(y_t)\n","\n","# --\n","# Model variables\n","batch_size = 64\n","n_epoch = 50\n","n_hidden = 600\n","\n","left_input = Input(shape=(max_seq_length,))\n","right_input = Input(shape=(max_seq_length,))\n","\n","embedding_layer = Embedding(len(train_df), embedding_dim, mask_zero=True, \n","                            input_shape=(max_seq_length,), trainable=True)\n","x_left = embedding_layer(left_input)\n","x_right = embedding_layer(right_input)\n","\n","#LSTM\n","shared_lstm = LSTM(n_hidden, dropout=0.5, return_state=True)\n","a, b, encoded_left = shared_lstm(x_left)\n","a, b, encoded_right = shared_lstm(x_right)\n","\n","cos_distance = Dot(axes = 1, normalize=True)([encoded_left, encoded_right])\n","cos_similarity = Reshape((1,))(cos_distance)\n","\n","model = Model(inputs=[left_input, right_input], outputs=[cos_similarity])\n","\n","es_cb = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n","\n","model.compile(optimizer=Adam(lr=0.001),\n","              loss='mean_squared_error',\n","              metrics=['mae'])\n","\n","history = model.fit([X_train['left'], X_train['right']], Y_train, epochs=n_epoch, batch_size=batch_size,\n","          validation_data=([X_validation['left'], X_validation['right']], Y_validation), callbacks=[es_cb])\n","#model.fit([X_train['left'], X_train['right']], train_labels, epochs=n_epoch, batch_size=batch_size, callbacks=[es_cb])\n","\n","\n","\n","t0 = []\n","t1 = []\n","test = clean_data('./drive/MyDrive/Colab Notebooks/test_data/STS.input.images.txt')\n","test_df = pd.DataFrame({'left' : [], 'right' : []})\n","test_df['left'] = test[0]\n","test_df['right'] = test[1]\n","\n","# Load training set\n","#for t in ['left', 'right']:\n","#    test_df[t + '_n'] = test_df[t]\n","\n","X_test = test_df[['left', 'right']]\n","#X_test = split_and_zero_padding(X, max_seq_length)\n","\n","test_labels = []\n","test_labels = gs_label(\"./drive/MyDrive/Colab Notebooks/test_data/STS.gs.images.txt\")\n","\n","Y_test = []\n","y_ts = []\n","for list in test_labels:\n","    for l in list:\n","        y_ts.append(float(l)/5)\n","Y_test = np.array(y_ts)\n","\n","output_list = model.predict(x=[X_test['left'], X_test['right']], batch_size=len(X_test['left']))\n","print(output_list)\n","with open(\"./drive/MyDrive/Colab Notebooks/test_data/STS.output_RNN.images.txt\", \"w\", encoding=\"utf-8\") as fw:\n","    for w in output_list:\n","        w = str(w)\n","        w = w.replace(\"[\", '')\n","        w = w.replace(\"]\", '')\n","        print(w, file=fw)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-064ec93634c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_layer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_layer_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/distribute/distributed_training_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0mrequests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \"\"\"\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0murllib3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchardet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from .connectionpool import (\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mHTTPConnectionPool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mHTTPSConnectionPool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpackages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpackages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m from .connection import (\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mport_by_scheme\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mDummyConnection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpackages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssl_match_hostname\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatch_hostname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCertificateError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m from .util.ssl_ import (\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mresolve_cert_reqs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mresolve_ssl_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mretry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRetry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from .url import (\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mget_host\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mparse_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/url.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLocationParseError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}